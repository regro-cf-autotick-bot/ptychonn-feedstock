{% set name = "PtychoNN" %}
{% set version = "0.3.7" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://github.com/mcherukara/PtychoNN/archive/v{{ version }}.tar.gz
  sha256: 89393cdbd3b9d624f844a670d60274fb4efb03286e747e592d02fe004fa3d2d3

build:
  entry_points:
    - ptychonn = ptychonn.__main__:main
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv
  number: 1

requirements:
  host:
    - pip
    - python {{ python_min }}
    - setuptools >=45
    - setuptools_scm
    - setuptools_scm_git_archive
    - toml
  run:
    - click
    - h5py
    - importlib-metadata
    - lightning >=2.1.3,<3
    - matplotlib-base
    - numpy >=1.21,<2
    - pandas
    - python >={{ python_min }}
    - pytorch >=1.12,<2.1
    - scikit-image
    - scikit-learn
    - scipy
    - tifffile
    - tqdm

test:
  imports:
    - ptychonn
  requires:
    - pip
    - python {{ python_min }}
  commands:
    - pip check
    - ptychonn --help

about:
  home: https://github.com/mcherukara/PtychoNN
  summary: Deep learning of ptychographic imaging
  description: >
    PtychoNN is a two-headed encoder-decoder network that simultaneously predicts sample amplitude and phase from input diffraction data alone. PtychoNN is 100s of times faster than iterative phase retrieval and can work with as little as 25X less data.

    Companion repository to the paper at: https://aip.scitation.org/doi/full/10.1063/5.0013065

  license: BSD-3-Clause
  license_family: BSD
  license_file: LICENSE
  dev_url: https://github.com/mcherukara/PtychoNN

extra:
  recipe-maintainers:
    - carterbox
    - mcherukara
